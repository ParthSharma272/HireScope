# ü§ó Deploy HireScope on Hugging Face Spaces (FREE FOREVER!)

Hugging Face Spaces is **100% free** with no time limits, perfect for ML/AI applications!

---

## üéÅ Why Hugging Face Spaces?

‚úÖ **Completely FREE forever** (no trial expiration!)  
‚úÖ **16 GB RAM** on free tier (32x more than Render!)  
‚úÖ **Perfect for ML models** (designed for AI apps)  
‚úÖ **No credit card required**  
‚úÖ **Community-focused** (great for portfolio)  
‚úÖ **Easy deployment** (Git-based)  
‚úÖ **Public or private** spaces  

---

## üöÄ Quick Deploy to Hugging Face

### Step 1: Create Hugging Face Account

1. Go to [huggingface.co](https://huggingface.co/)
2. Sign up (free account)
3. Verify email

### Step 2: Create a New Space

1. Click your profile ‚Üí **"New Space"**
2. **Space name**: `hirescope-backend`
3. **License**: MIT or Apache 2.0
4. **SDK**: Select **"Docker"**
5. **Visibility**: Public (or Private if you have PRO)
6. Click **"Create Space"**

### Step 3: Connect Your Repository

**Option A: Direct Git Push**

```bash
# Add Hugging Face remote
git remote add hf https://huggingface.co/spaces/YOUR_USERNAME/hirescope-backend

# Push backend code
git subtree push --prefix backend hf main
```

**Option B: Manual File Upload**

1. Go to your Space ‚Üí **"Files"** tab
2. Upload files from `backend/` directory
3. Make sure to upload all Python files and requirements.txt

### Step 4: Create Dockerfile

Hugging Face Spaces uses Docker. Create this file in your Space:

**`Dockerfile`** (in the Space root):

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Download spaCy model
RUN python -m spacy download en_core_web_sm

# Copy application code
COPY . .

# Expose port
EXPOSE 7860

# Start command (Hugging Face uses port 7860)
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "7860"]
```

### Step 5: Create README.md

Hugging Face requires a README with metadata:

**`README.md`** (in the Space root):

```markdown
---
title: HireScope Backend
emoji: üìÑ
colorFrom: purple
colorTo: blue
sdk: docker
app_port: 7860
---

# HireScope Backend

AI-powered resume analysis API built with FastAPI and sentence-transformers.

## Features
- Semantic resume analysis
- ATS compatibility checking
- AI template generation
- Batch resume processing

## API Documentation
Once running, visit `/docs` for interactive API documentation.
```

### Step 6: Deploy!

Push your changes and Hugging Face will automatically build and deploy:

```bash
git add Dockerfile README.md
git commit -m "Add Hugging Face deployment config"
git push hf main
```

**Your Space URL**: `https://YOUR_USERNAME-hirescope-backend.hf.space`

---

## üîß Alternative: Hugging Face Inference API

You can also use Hugging Face's free Inference API instead of hosting:

1. **Get API Token**: Profile ‚Üí Settings ‚Üí Access Tokens
2. **Use Hosted Models**: No need to host embeddings yourself
3. **Update backend** to use HF Inference API

This reduces memory usage significantly!

---

## üì¶ Other FREE Forever Options

### 1. **Google Cloud Run** (Best Alternative)

‚úÖ **2 million requests/month FREE**  
‚úÖ **Up to 8 GB RAM**  
‚úÖ **Scales to zero** (no cold starts after first use)  
‚ö†Ô∏è Requires credit card (but won't charge in free tier)  

**Setup**:
```bash
# Install gcloud CLI
brew install google-cloud-sdk

# Login
gcloud auth login

# Deploy
gcloud run deploy hirescope-backend \
  --source ./backend \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

### 2. **Oracle Cloud Free Tier**

‚úÖ **Always FREE** (not a trial!)  
‚úÖ **24 GB RAM** across instances  
‚úÖ **200 GB bandwidth/month**  
‚ö†Ô∏è More complex setup  

**What you get**:
- 2 AMD-based VMs (1 GB RAM each)
- OR 4 ARM-based VMs (24 GB RAM total!)
- Always free, no expiration

### 3. **Deta Space**

‚úÖ **Completely FREE**  
‚úÖ **No credit card**  
‚úÖ **Easy deployment**  
‚ö†Ô∏è Limited to smaller apps  

### 4. **Koyeb**

‚úÖ **Free tier forever**  
‚úÖ **512 MB RAM** (same as Render)  
‚úÖ **No sleep mode**  
‚ö†Ô∏è Still might have memory issues  

---

## üèÜ Best Options Ranked (FREE Forever)

### For HireScope with 8+ GB RAM Needed:

1. **ü•á Hugging Face Spaces** ‚≠ê BEST CHOICE
   - FREE forever
   - 16 GB RAM
   - Perfect for ML
   - No credit card needed

2. **ü•à Google Cloud Run**
   - FREE tier (2M requests/month)
   - 8 GB RAM
   - Requires credit card (no charges in free tier)
   - Professional solution

3. **ü•â Oracle Cloud Free Tier**
   - Always FREE (24 GB RAM with ARM instances)
   - More complex setup
   - Great once configured

### For Optimized Smaller Model (<512 MB):

4. **Koyeb** (512 MB, no sleep)
5. **Render** (512 MB, sleeps after 15 min)
6. **Fly.io** (256 MB)

---

## üí° My Recommendation

### Best Solution: Hugging Face Spaces ü§ó

**Why?**
- ‚úÖ **100% FREE FOREVER**
- ‚úÖ **16 GB RAM** (perfect for your ML models)
- ‚úÖ **No credit card needed**
- ‚úÖ **Easy deployment** (just push to Git)
- ‚úÖ **Great for portfolio** (hosted on AI platform)
- ‚úÖ **Built for ML apps** (perfect fit!)

**Setup Time**: 15 minutes  
**Cost**: $0 forever  
**Reliability**: Excellent  

### Second Best: Google Cloud Run

**Why?**
- ‚úÖ Always free tier (2M requests/month)
- ‚úÖ Professional infrastructure
- ‚úÖ 8 GB RAM
- ‚ö†Ô∏è Requires credit card (but no charges)

---

## üéØ Quick Start Guide

### Deploy to Hugging Face (Recommended)

```bash
cd /Users/parth/Desktop/HireScope

# 1. Create Dockerfile for HF
cat > backend/Dockerfile << 'EOF'
FROM python:3.11-slim
WORKDIR /app
RUN apt-get update && apt-get install -y build-essential && rm -rf /var/lib/apt/lists/*
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN python -m spacy download en_core_web_sm
COPY . .
EXPOSE 7860
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "7860"]
EOF

# 2. Create HF README
cat > backend/README.md << 'EOF'
---
title: HireScope Backend
emoji: üìÑ
colorFrom: purple
colorTo: blue
sdk: docker
app_port: 7860
---
# HireScope Backend API
EOF

# 3. Commit
git add backend/Dockerfile backend/README.md
git commit -m "Add Hugging Face Spaces deployment config"

# 4. Sign up at huggingface.co
# 5. Create new Space (Docker SDK)
# 6. Push to HF (instructions in your Space)
```

---

## üÜö Cost Comparison (Forever)

| Service | RAM | Cost | Credit Card? | Best For |
|---------|-----|------|--------------|----------|
| **HF Spaces** | 16 GB | **$0** ‚úÖ | No ‚úÖ | **ML/AI apps** |
| Google Cloud Run | 8 GB | $0* | Yes | Professional apps |
| Oracle Free Tier | 24 GB | $0* | Yes | Advanced users |
| Railway | 8 GB | **$5/mo** ‚ùå | Yes after trial | Easy setup |
| Render | 512 MB | $0 | No | Small APIs |
| Vercel Functions | 1 GB | $0 | No | Serverless |

*Free tier, won't charge unless you upgrade

---

## üìñ Documentation Links

- **Hugging Face Spaces**: https://huggingface.co/docs/hub/spaces
- **Google Cloud Run**: https://cloud.google.com/run/docs
- **Oracle Cloud Free**: https://www.oracle.com/cloud/free/

---

## üéâ Summary

**For HireScope Backend:**

**üèÜ Best Choice: Hugging Face Spaces**
```
‚úÖ FREE FOREVER (no trial expiration!)
‚úÖ 16 GB RAM (perfect for ML models)
‚úÖ No credit card required
‚úÖ Easy Git-based deployment
‚úÖ Great for AI/ML portfolio
‚úÖ Community focused
```

**Setup Steps:**
1. Sign up at huggingface.co (free)
2. Create new Space (Docker SDK)
3. Add Dockerfile + README
4. Push your code
5. Done! üéâ

**Your URL**: `https://YOUR_USERNAME-hirescope-backend.hf.space`

---

**ü§ó Go with Hugging Face Spaces - it's made for apps like yours!**

**Last Updated**: November 1, 2025
